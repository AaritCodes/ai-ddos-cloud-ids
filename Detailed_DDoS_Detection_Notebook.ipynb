{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0b8778",
   "metadata": {},
   "source": [
    "# AI-Driven DDoS Detection in Cloud Environments Using Machine Learning\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project presents the design and implementation of an intelligent Intrusion Detection System (IDS) capable of detecting Distributed Denial-of-Service (DDoS) attacks in cloud computing environments using Machine Learning techniques.\n",
    "\n",
    "Cloud infrastructures are highly vulnerable to DDoS attacks, where malicious actors flood servers with massive traffic to exhaust bandwidth, computing resources, and service availability. Traditional rule-based detection systems often fail to identify evolving and zero-day attack patterns.\n",
    "\n",
    "To address this limitation, this project leverages supervised Machine Learning algorithms trained on real network traffic flow datasets to automatically classify traffic as benign or malicious.\n",
    "\n",
    "The system analyzes statistical flow features such as packet counts, byte rates, duration metrics, and protocol behavior to identify abnormal traffic patterns associated with DDoS attacks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e9e8a",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "The dataset used in this project is derived from the CIC-DDoS2019 intrusion detection dataset, which contains labeled network traffic flows representing various DDoS attack types and benign traffic.\n",
    "\n",
    "The dataset is stored in **Parquet format**, a columnar storage file type optimized for high-performance data analytics.\n",
    "\n",
    "Each row in the dataset represents a network traffic flow, and each column represents a statistical feature extracted from packet capture data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeef160",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"/kaggle/input/cicddos2019/UDP-training.parquet\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a76b041",
   "metadata": {},
   "source": [
    "## Dataset Inspection and Exploratory Analysis\n",
    "\n",
    "Before training Machine Learning models, it is essential to understand the structure and composition of the dataset.\n",
    "\n",
    "In this step, we examine:\n",
    "\n",
    "- Dataset dimensions  \n",
    "- Feature names  \n",
    "- Label distribution  \n",
    "\n",
    "This helps identify class imbalance issues and validates dataset readiness for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85768ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nColumns:\\n\", data.columns)\n",
    "\n",
    "print(\"\\nLabel Distribution:\\n\")\n",
    "print(data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e6427",
   "metadata": {},
   "source": [
    "## Feature and Target Separation\n",
    "\n",
    "Machine Learning models require input features (independent variables) and output labels (dependent variable).\n",
    "\n",
    "- Features (X): Traffic characteristics  \n",
    "- Target (y): Attack classification label  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295debb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Label', axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cdc04",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "\n",
    "Textual labels must be converted into numerical form so that Machine Learning models can process them mathematically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80849964",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The dataset is divided into training and testing subsets to evaluate model performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99476c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train Shape:\", X_train.shape)\n",
    "print(\"Test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ae2a9",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Feature scaling standardizes feature ranges, improving model convergence and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16358f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a6043",
   "metadata": {},
   "source": [
    "## Random Forest Model Training\n",
    "\n",
    "Random Forest is an ensemble classifier that constructs multiple decision trees and outputs majority predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef37519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9dfa98",
   "metadata": {},
   "source": [
    "## Traffic Prediction\n",
    "\n",
    "The trained model is used to classify unseen traffic samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837bcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454401d",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluation metrics include Accuracy, Precision, Recall, and F1â€‘Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fe81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b7cd8",
   "metadata": {},
   "source": [
    "## Confusion Matrix Visualization\n",
    "\n",
    "A confusion matrix visualizes classification performance and misclassification patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5888ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
